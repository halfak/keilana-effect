Beyond this demonstration, I would like to use this dataset and method to explore article quality inflection points that occur in other cross sections of Wikipedia.  As was discussed, I was surprised to learn about the temporal proximity (and apparent effectiveness) of Keilana's efforts since I had discovered the inflection that started around her initiatives independently.  Other ``Keilana Effect''s should also become evident when re-applying this analysis method.  Doing so would allow the Wikimedia Foundation and other organizations that support initiatives (like the grant that supported User:Keilana) to bring attention and resources to efforts that are already working far better than expected.

Beyond looking for inflection points, we can also simply look for gaps to target effort towards.  In the past, determining where a coverage gap might be and how big large the gap is would require massive effort on the part of Wikipedians to assess thousands of articles.  And worse, it would be nearly impossible to find out when the gap originated and whether or not it seemed to be widening or closing.  Using this dataset and method, researchers can explore the largest gaps in coverage in Wikipedia and organizations like the Wikimedia Foundation can target new outreach campaigns (like Inspire campaigns\footnote{https://meta.wikimedia.org/wiki/Grants:IdeaLab/Inspire}) to improve coverage in areas with known gaps.

This modeling approach also makes research around the nature of Wikipedia's quality dynamics easier.  For example, using this modeling strategy, one could replicate or extend the modeling work performed by Kittur et al.~\cite{kittur08harnessing} and Arazy \& Nov~\cite{arazy10determinants} without resorting to propensity modeling, with far more observations, and in time scales where Wikipedian assessments are sparse.  By developing and releasing this dataset, I intend to make exactly this type of work easier.
